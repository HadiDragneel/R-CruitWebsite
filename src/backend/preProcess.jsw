const tf = require("@tensorflow/tfjs");
const use = require('@tensorflow-models/universal-sentence-encoder');

export async function tokenize() {
    const ToDos = [
        "Hit the gym",
        "Go for a run",
        "Study Math",
        "Watch Biology lectures",
        "Date with Michele",
        "Have dinner with Pam",
    ]

    const list_sentences = [
        // Smartphones
        "I like my phone",
        "My phone is not good.",
        "Your cellphone looks great.",

        // Weather
        "Will it snow tomorrow?",
        "Recently a lot of hurricanes have hit the US",
        "Global warming is real",

        // Food and health
        "An apple a day, keeps the doctors away",
        "Eating strawberries is healthy",
        "Is paleo better than keto?",

        // Asking about age
        "How old are you?",
        "what is your age?"
    ];

    const model = await use.load()
    const todoEmbedding = await model.embed(list_sentences)
    console.log(todoEmbedding.shape)


    const similarityScore = async (sentenceAIndex, sentenceBIndex, embeddings) => {
        const sentenceAEmbeddings = embeddings.slice([sentenceAIndex, 0], [1])
        const sentenceBEmbeddings = embeddings.slice([sentenceBIndex, 0], [1])
        const sentenceATranspose = false
        const sentenceBTransepose = true
        const scoreData = await sentenceAEmbeddings
            .matMul(sentenceBEmbeddings, sentenceATranspose, sentenceBTransepose)
            .data()
        return scoreData[0]
    }

    const todoEmbeddings = await model.embed(list_sentences)
    const firstPairScore = await similarityScore(0, 1, todoEmbeddings)
    console.log(`${list_sentences[0]}\n${list_sentences[1]}\nsimilarity: ${firstPairScore}`)
}

